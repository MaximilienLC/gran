{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77d672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We report the target pre-trained behaviour of the paper\n",
    "# 'Generative Adversarial Neuroevolution to Imitate Control Behaviour'.\n",
    "# They come from Stable Baselines 3\n",
    "# (https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/benchmark.md).\n",
    "# Below is the evaluation of all available agents on each task.\n",
    "# We picked the strongest one to imitate on each task.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append(os.path.abspath('') + '/../../..')\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from sb3_contrib import TQC, QRDQN\n",
    "from stable_baselines3 import A2C, DDPG, DQN, PPO, SAC, TD3\n",
    "import torch\n",
    "\n",
    "from utils.functions.control import get_task_name\n",
    "\n",
    "homedir = os.path.expanduser('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8665fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model_name, task):\n",
    "\n",
    "    task_name = get_task_name(task)\n",
    "\n",
    "    path = homedir + '/rl-baselines3-zoo/rl-trained-agents/' + model_name\n",
    "    path += '/' + task_name + '_1/' + task_name + '.zip'\n",
    "    custom_objects = {'learning_rate': 0.0,\n",
    "                      'lr_schedule': lambda _: 0.0,\n",
    "                      'clip_range': lambda _: 0.0}\n",
    "\n",
    "    if model_name == 'a2c':\n",
    "        model = A2C.load(path, custom_objects=custom_objects)\n",
    "    elif model_name == 'ddpg':\n",
    "        model = DDPG.load(path, custom_objects=custom_objects)\n",
    "    elif model_name == 'dqn':\n",
    "        model = DQN.load(path, custom_objects=custom_objects)\n",
    "    elif model_name == 'ppo':\n",
    "        model = PPO.load(path, custom_objects=custom_objects)\n",
    "    elif model_name == 'qrdqn':\n",
    "        model = QRDQN.load(path, custom_objects=custom_objects)\n",
    "    elif model_name == 'sac':\n",
    "        model = SAC.load(path, custom_objects=custom_objects)\n",
    "    elif model_name == 'td3':\n",
    "        model = TD3.load(path, custom_objects=custom_objects)\n",
    "    else: # model == 'tqc':\n",
    "        model = TQC.load(path, custom_objects=custom_objects)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e5a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, model, nb_tests=10, max_nb_states=2**31-1, render=False,\n",
    "    track_rewards=False):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    rewards = np.empty((1, 0)).tolist()\n",
    "\n",
    "    for i in range(nb_tests):\n",
    "\n",
    "        env.seed(2**31-1-i)\n",
    "        np.random.seed(2**31-1-i)\n",
    "        torch.manual_seed(2**31-1-i)\n",
    "        random.seed(2**31-1-i)\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        score = 0\n",
    "        done = False\n",
    "        nb_states = 0\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            action, _ = model.predict(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            score += reward\n",
    "            if i == 0:\n",
    "                rewards[i].append(reward)\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(0.01)\n",
    "\n",
    "            nb_states += 1\n",
    "\n",
    "            if nb_states == max_nb_states:\n",
    "                break\n",
    "\n",
    "        scores.append(score)\n",
    "        \n",
    "    if track_rewards:\n",
    "        with open('../../../data/states/envs.multistep.imitate.control/' + \\\n",
    "            'extra/sb3_agent_rewards/' + \\\n",
    "            re.sub('(?<!^)(?=[A-Z])', '_', env.spec._env_name).lower() + \\\n",
    "            '/rewards.pkl', 'wb') as f:\n",
    "            pickle.dump(rewards, f)\n",
    "\n",
    "    return '-> ' + str(np.round(np.mean(scores), 1)) + '±' + \\\n",
    "        str(np.round(np.std(scores), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b2d90",
   "metadata": {},
   "source": [
    "# Acrobot-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c44dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> -81.0±12.8\n",
      "DQN -> -80.4±8.6\n",
      "PPO -> -89.0±23.7\n",
      "QRDQN -> -81.5±16.7\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Acrobot-v1')\n",
    "\n",
    "model = load('a2c', 'acrobot')\n",
    "print('A2C ' + evaluate(env, model) )\n",
    "\n",
    "model = load('dqn', 'acrobot')\n",
    "print('DQN ' + evaluate(env, model, track_rewards=True) )\n",
    "\n",
    "model = load('ppo', 'acrobot')\n",
    "print('PPO ' + evaluate(env, model) )\n",
    "\n",
    "model = load('qrdqn', 'acrobot')\n",
    "print('QRDQN ' + evaluate(env, model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116bca1",
   "metadata": {},
   "source": [
    "# CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bfd56bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> 500.0±0.0\n",
      "DQN -> 500.0±0.0\n",
      "PPO -> 500.0±0.0\n",
      "QRDQN -> 500.0±0.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "model = load('a2c', 'cart_pole')\n",
    "print('A2C ' + evaluate(env, model) )\n",
    "\n",
    "model = load('dqn', 'cart_pole')\n",
    "print('DQN ' + evaluate(env, model) )\n",
    "\n",
    "model = load('ppo', 'cart_pole')\n",
    "print('PPO ' + evaluate(env, model, track_rewards=True) )\n",
    "\n",
    "model = load('qrdqn', 'cart_pole')\n",
    "print('QRDQN ' + evaluate(env, model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a74457",
   "metadata": {},
   "source": [
    "# MountainCar-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8034a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> -200.0±0.0\n",
      "DQN -> -119.9±23.5\n",
      "PPO -> -200.0±0.0\n",
      "QRDQN -> -128.7±31.7\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "\n",
    "model = load('a2c', 'mountain_car')\n",
    "print('A2C ' + evaluate(env, model) ) # -111.3\t24.1\n",
    "\n",
    "model = load('dqn', 'mountain_car')\n",
    "print('DQN ' + evaluate(env, model, track_rewards=True) )\n",
    "\n",
    "model = load('ppo', 'mountain_car')\n",
    "print('PPO ' + evaluate(env, model) ) # -110.4\t19.473\n",
    "\n",
    "model = load('qrdqn', 'mountain_car')\n",
    "print('QRDQN ' + evaluate(env, model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e1573",
   "metadata": {},
   "source": [
    "# MountainCarContinuous-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c045b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> -99.9±0.0\n",
      "DDPG -> 93.5±0.1\n",
      "PPO -> -18.7±0.7\n",
      "SAC -> 94.6±1.0\n",
      "TD3 -> 93.4±0.1\n",
      "TQC -> 83.9±30.9\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "\n",
    "model = load('a2c', 'mountain_car_continuous')\n",
    "print('A2C ' + evaluate(env, model) ) # 91.2\t0.3\n",
    "\n",
    "model = load('ddpg', 'mountain_car_continuous')\n",
    "print('DDPG ' + evaluate(env, model) )\n",
    "\n",
    "model = load('ppo', 'mountain_car_continuous')\n",
    "print('PPO ' + evaluate(env, model) ) # 88.3\t2.6\n",
    "\n",
    "model = load('sac', 'mountain_car_continuous')\n",
    "print('SAC ' + evaluate(env, model, track_rewards=True) )\n",
    "\n",
    "model = load('td3', 'mountain_car_continuous')\n",
    "print('TD3 ' + evaluate(env, model) )\n",
    "\n",
    "model = load('tqc', 'mountain_car_continuous')\n",
    "print('TQC ' + evaluate(env, model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7107a",
   "metadata": {},
   "source": [
    "# Pendulum-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45bc0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> -1593.8±21.3\n",
      "DDPG -> -149.5±60.6\n",
      "PPO -> -206.9±76.8\n",
      "SAC -> -176.7±64.5\n",
      "TD3 -> -154.1±64.4\n",
      "TQC -> -150.6±61.2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v1')\n",
    "\n",
    "model = load('a2c', 'pendulum')\n",
    "print('A2C ' + evaluate(env, model) ) # -163.0\t103.2\n",
    "\n",
    "model = load('ddpg', 'pendulum')\n",
    "print('DDPG ' + evaluate(env, model) )\n",
    "\n",
    "model = load('ppo', 'pendulum')\n",
    "print('PPO ' + evaluate(env, model) )\n",
    "\n",
    "model = load('sac', 'pendulum')\n",
    "print('SAC ' + evaluate(env, model) )\n",
    "\n",
    "model = load('td3', 'pendulum')\n",
    "print('TD3 ' + evaluate(env, model) )\n",
    "\n",
    "model = load('tqc', 'pendulum')\n",
    "print('TQC ' + evaluate(env, model, track_rewards=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36b147",
   "metadata": {},
   "source": [
    "# LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6202277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> 150.8±132.3\n",
      "DQN -> 115.0±103.1\n",
      "PPO -> 142.7±21.0\n",
      "QRDQN -> 156.4±133.1\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "model = load('a2c', 'lunar_lander')\n",
    "print('A2C ' + evaluate(env, model) )\n",
    "\n",
    "model = load('dqn', 'lunar_lander')\n",
    "print('DQN ' + evaluate(env, model) )\n",
    "\n",
    "model = load('ppo', 'lunar_lander')\n",
    "print('PPO ' + evaluate(env, model, track_rewards=True) ) # 242.1  31.8\n",
    "\n",
    "model = load('qrdqn', 'lunar_lander')\n",
    "print('QRDQN ' + evaluate(env, model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2227a",
   "metadata": {},
   "source": [
    "# LunarLanderContinuous-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc82a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> -102.5±17.5\n",
      "DDPG -> 194.4±147.7\n",
      "PPO -> 128.7±41.4\n",
      "SAC -> 269.7±20.4\n",
      "TD3 -> 228.8±50.8\n",
      "TQC -> 239.1±75.2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "\n",
    "model = load('a2c', 'lunar_lander_continuous')\n",
    "print('A2C ' + evaluate(env, model) ) # 84.2\t145.9\n",
    "\n",
    "model = load('ddpg', 'lunar_lander_continuous')\n",
    "print('DDPG ' + evaluate(env, model) )\n",
    "\n",
    "model = load('ppo', 'lunar_lander_continuous')\n",
    "print('PPO ' + evaluate(env, model) )\n",
    "\n",
    "model = load('sac', 'lunar_lander_continuous')\n",
    "print('SAC ' + evaluate(env, model, track_rewards=True) )\n",
    "\n",
    "model = load('td3', 'lunar_lander_continuous')\n",
    "print('TD3 ' + evaluate(env, model) )\n",
    "\n",
    "model = load('tqc', 'lunar_lander_continuous')\n",
    "print('TQC ' + evaluate(env, model) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065d824b",
   "metadata": {},
   "source": [
    "# Swimmer-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73e9b507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2C -> 122.9±5.7\n",
      "SAC -> 334.6±2.8\n",
      "TD3 -> 358.3±1.6\n",
      "TQC -> 328.7±1.7\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Swimmer-v3')\n",
    "\n",
    "model = load('a2c', 'swimmer')\n",
    "print('A2C ' + evaluate(env, model) )\n",
    "\n",
    "# ValueError: Error: Unexpected observation shape (8,) for Box environment,\n",
    "# please use (9,) or (n_env, 9) for the observation shape.\n",
    "# model = load('ppo', 'swimmer')\n",
    "# print('PPO ' + evaluate(env, model) ) # 281.6\t9.7\n",
    "\n",
    "model = load('sac', 'swimmer')\n",
    "print('SAC ' + evaluate(env, model) )\n",
    "\n",
    "model = load('td3', 'swimmer')\n",
    "print('TD3 ' + evaluate(env, model, track_rewards=True) )\n",
    "\n",
    "model = load('tqc', 'swimmer')\n",
    "print('TQC ' + evaluate(env, model) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2aa5efa1634584d1dc9ab74356fcd13ce70b1b290d2634458c70c94aa8141edd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
